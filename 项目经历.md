美餐业务系统 (in Meican)

// before
developer
项目描述：作为开发者一员 , 支撑美餐(https://meican.com)产品线食堂组的业务后端,业务包括菜品商店, 支付下单,运营后端, 账务数据分析和展示,支持的产品端包括小程序,app,硬件,web,业务线每天需要处理数十万笔交易订单,每个周期负责各方对帐,整个系统开发于 Cloud Native, 运行在微服务,其中本人负责设计开发的账务系统包含了数据同步中使用流式处理, 清洗聚合展示 ,还有一些批量任务, 对不同的业务实体进行隔离,对接第三方支付平台实现对账,使用了本人自己开发的分布式调度平台调度批处理任务,使用自己开发的异步任务库处理异步任务, 将中间数据和财务报表上传到aws(dynamodb,s3)供用户下载,开发了分布式调度平台, 调度模块使用时间轮实现, 可同时支持上几千个任务调度, 分布式的部分实现参考了grpc负载均衡的代码设计




主要工作: \n ① 参与核心部分代码编写,负责设计开发了其中的账户系统, 做 oncall, 独立负责该系统的系统设计, 开发, 部署上线,配置监控\n ② 辅助其他系统的业务模块开发,架构讨论,参与产品和需求讨论, 和其他模块系统设计的讨论, 负责整个业务系统的维护监控, 调优, bug修复,sql 优化等,保证系统平稳运行 \n③ 负责开发了内部工具, 使用docker打包各种服务供测试和调度使用,写过一些dockerfile \n④ 搭建配置测试环境, 维护测试坏境正常运行, 包括前端项目的部署和配置, 保证测试数据的正确 \n ⑤ 参与应对服务规模提升做出架构的调整 \n ⑥ 写脚本批量修复数据库数据数据


TechStack: golang,python,shell,postgres,Kubernetes,terraform,nacos,argo,gitlab,docker,pulsar,redis, grpc,gin, postgres,nginx,etcd,AWS


// after
作为中国大陆从事外卖业务的互联网公司,服务于上千个餐厅和企业超过百万用户,本项目是关于食堂组的业务后端,由菜品商店, 支付下单,运营后端, 账务数据分析和展示,支持的产品端包括小程序,等大小10几个复杂模块组成。系统是基于Cloud Native 部署的，由6个主要的微服务构建而成，基于grpc通信，能够同时支持2000个后台任务进行异步调度执行，每日QPS峰值达几w

\n① 独立设计开发了其中的账户模块 ,括数据库设计，Kubernetes 部署等。并参与团队剩余模块的实现，提供优化方案 \n② 与系统的维护，部署监控，性能优化，和故障处理。保证系统有可用99%。\n③ 负责开发了内部工具, 比如提供测试人员使用docker脚本, 开发内部基础设施分布式调度平台, 开发内部使用的库\n④ 相关DevOps工作，比如搭建维护配置测试环境\n⑤ 参与系统后续优化，扩容方案设计，以支持最高峰值上万的用户

技术栈: Golang，Python，Shell，Kubernetes，Docker，Terraform，Redis，Postgres，Etcd，Grpc，Nginx，Git




// before 
皮皮虾后端业务系统 (in 字节跳动):
项目描述： 搞笑娱乐社区APP, 业务推送组后端业务, 出海东南亚. 业务端的主要服务是有关 文章, 评论, 视频, 数据流聚合和推送. 组内自己负责一些infra维护. 用户数量百万级别. 

主要工作: \n ① 开发和调优相关的模块,作为oncall多次参与报警的监视和处理 ② 独立开发了用户历史记录浏览模块,支撑百万级用户新数据的半实时推送 \n ③ 技术调研, 内部基础平台的调研选型调研,撰写书面报告 \n ③ 负责一些运营数据的分析和组内对于数据的监控,搭建promethus并收集数据到grafana. \n ④ 参与过春节红包的技术架构设计. 

技术栈: golang,graph sql, mysql, nginx, kafka,hive,redis


// after

\n该项目是一个在中国和东南亚拥有300百万用户的搞笑娱乐社区APP, 后端组负责业务推送相关服务推送信息包括文章, 评论, 视频等, 
\n 主要工作
\n ① 开发和调优\n ② 技术调研, 内部基础平台的调研选型调研,撰写书面报告 \n ③ 负责一些运营数据的分析和组内对于数据的监控,搭建promethus并收集数据到grafana. \n ④ 参与多次在线事故处理\n 技术栈：Golang，GraphQL，MySQL, Redis，Kafka，Nginx






// before
(search group)京东:
项目描述: group 主要的工作是维护一个搜索引擎,从上游的数据生产组同步数据, 然后根据业务和领域进行索引并分库维护数据, 通过很多自动化的脚本,保证日常数据流的正确. 并各方提供数据,同时为各端提供后端接口, 提供数据的查询
主要工作: \n ① 开发和维护自动化脚本,监控各方业务流程流程,必要时手动处理保证流程正确 \n ② 据维护搜索结果优化并撰写书面报告\n ③ 根据突发流量对各种资源扩容和缩容, 打折促销日支持的突发日增量订单数据仅索引数据可达TB级别 \n ④ 开发业务模块, 提供数据查询和分析 ⑤ 负责优化定制thrift rpc, 为业务级别做smart client 进行集群分发
技术栈: c++, thrift, python, shell, linux, shell, sql

// after
项目描述：:group 主要的工作是维护一个搜索引擎,对从上游的每日TB级数据进行同步,然后根据业务和领域进行索引并分库维护数据, 通过很多自动化的脚本,保证日常数据流的正确. 并为其他团队提供数据和相关的查询API
\n ① 开发和维护自动化脚本,监控各方业务流程流程,必要时手动处理保证流程正确\n ② 据维护搜索结果优化并撰写书面报告\n ③ 根据突发流量对各种资源扩容和缩容, 以应对打折促销日支持的突增100%的日增量订单 ④ 开发业务模块, 定制thrift rpc 对数据进行广播发送。
 技术栈: C++，Python，Shell，Linux，Thrift，SQL




// before
(高速录取) 中国船舶工业系统研究院:
项目描述: 舰船通信软件, 基于C++ QT库的客户端软件, 移植多平台(linux,window, 国产嵌入式实时操作系统), 该软件用于用户定制军事指令协议,作为一个数据分发的网关, 对数据包的进行协议识别进行智能路由, 开发除了QT平台不允许使用现成的开源库, 完全基于自己定制

主要工作: 作为项目负责人独立承担设计和开发工作, 实现简单的集群互备和健康检查,以及数据同步操作, 撰写项目文档, 提交评审并答辩, 负责后续需求沟通和迭代开发
技术栈: C++, QT, UDP ,TCP, linux

 舰船通信软件, 基于C++ QT库的客户端软件, 移植多平台(linux,window, 国产嵌入式实时操作系统), 该软件用于用户定制军事指令协议,作为一个数据分发的网关, 对数据包的进行协议识别进行智能路由 

 主要工作: 作为项目负责人独立承担设计和开发工作, 实现简单的集群互备和健康检查,以及数据同步操作, 撰写项目文档, 负责后续需求沟通和迭代开发



自我介绍:
\n① 熟悉后端开发相关技术和流程, 熟悉微服务,云原生开发,熟悉sql优化, 和后端服务业务或者技术调优\n② 有良好的代码风格，注重代码质量, 熟悉多种编程范式\n③ 动手能力强, 会为了兴趣去学习新的技术,接受经常在不熟悉的领域工作, 作为后端程序员工作中会修改一些前端代码,也做过开发过区块链相关的技术开发\n④ 有扎实的计算机理论基础，良好的算法与数据结构基础，了解计算机基本原理与常见机制。\n⑤ 本人对交易以及区块链以及数字加密货币领域很感兴趣, 做过很多相关开发





① 熟悉后端开发相关技术和流程, 熟悉微服务,云原生开发,熟悉sql优化, 和后端服务业务或者技术调优,经历过很多项目
① Be familiar with Backend technology and related develop process, be familiar with Micro service, Cloud-Native , experienced in optimization of sql, or ralated backend technology, though I use them in project frequently

② 有良好的代码风格，注重代码质量, 熟悉多种编程范式
② Good coding habit, Focus on code quality, be familiar with paradigm
③ 动手能力强, 会为了兴趣去学习新的技术,接受经常在不熟悉的领域工作, 作为后端程序员工作中会修改一些前端代码,也做过开发过区块链相关的技术开发
③ Strong hands-on ability,  learn some technology just for interest, willing to work in unfamiliar field, as a backend developer, as like I may fix some fronted code in work, or I have also done some blockchain related development
④ 有扎实的计算机理论基础，良好的算法与数据结构基础，了解计算机基本原理与常见机制。
④ I had solid foundations in data structure and algorithms with decent knowledge in basic computer theory.
⑤ 工作中主动了解解决问题, 主动沟通, 不给自己设立边界,态度积极
⑤ Proactively understand and solve problems at work, actively communicate, do not set boundaries for myselves, and have a positive work attitude

① Be familiar with Backend technology and related develop process, be familiar with Micro service, Cloud-Native , experienced in optimization of sql, or ralated backend technology, though I use them in project frequently. \n② Good coding habit, Focus on code quality, be familiar with paradigm. \n③ Strong hands-on ability, learn some technology just for interest, willing to work in unfamiliar field, as a backend developer, as like I may fix some fronted code in work, or I have also done some blockchain related development. \n④ I had solid foundations in data structure and algorithms with decent knowledge in basic computer theory.\n⑤ Proactively understand and solve problems at work, actively communicate, do not set boundaries for myselves, and have a positive work attitude.









Developed new procedures for requirements gathering, needs analysis, testing, scripting and documentation to strengthen quality and functionality of business-critical applications.
制定了新的需求收集、需求分析、测试、脚本编写和文档编制程序，以加强关键业务应用程序的质量和功能


Developed large-scale, portable, thread-safe and ultra-high performance foundation and application infrastructure libraries.
开发了大规模、可移植、线程安全和超高性能的基础和应用基础架构库。


Developed a distributed real-time news recommendation system using XXX, XXX, and XXX with QPS over XXX;
开发了一个基于XXX、XXX和XXX的分布式实时新闻推荐系统，QPS over XXX；

Used Hadoop, Kafka, Cassandra, and Storm to develop a lambda architecture that enables real-time big data processing that is highly available, scalable and extensible.
使用Hadoop、Kafka、Cassandra和Storm开发了一个lambda架构，该架构支持高可用、可伸缩和可扩展的实时大数据处理。

In my role as Computer Programmer I had a number of day-to-day responsibilities that included write special code, test written code and execute them, participated in the design, testing and installing client servers, mentored trainee Computer Programmers and worked on developing cyber security infrastructures for internal and external clients.

在我担任计算机程序员期间，我承担了许多日常职责，包括编写特殊代码、测试编写的代码并执行它们，参与设计、测试和安装客户端服务器，指导见习计算机程序员，并致力于为内部和外部客户开发网络安全基础设施。





作为中国大陆从事外卖业务的互联网公司,服务于上千个餐厅和企业超过百万用户,本项目是关于食堂组的业务后端,由菜品商店, 支付下单,运营后端, 账务数据分析和展示,等大小10几个复杂模块组成。系统是基于Cloud Native 部署的，由6个主要的微服务构建而成，基于grpc通信，能够同时支持2000个后台任务进行异步调度执行，每日QPS峰值达十几w


As an Internet company engaged in takeout business in Chinese Mainland, it serves more than one million users in thousands of restaurants and enterprises. This project is about the business back-end of the canteen group, which is composed of 10 complex modules, including food stores, payment and ordering, operation back-end, accounting data analysis and display, etc. The system is deployed based on Cloud Native. It is built from six major microservices. which internal communication based on grpc , where bills system which I charged can support 2000 background tasks for asynchronous scheduling and execution at the same time. with a daily peak of more than 100000 QPS



① 独立设计开发了其中的账户模块 ,括数据库设计，Kubernetes 部署等。并参与团队剩余模块的实现，提供优化方案 
② 参与系统的维护，部署监控，性能优化，和故障处理。保证系统有可用99%。
③ 负责开发了内部工具, 比如提供测试人员使用docker脚本, 开发内部基础设施分布式调度平台, 开发内部使用的库
④ 相关DevOps工作，比如搭建维护配置测试环境
⑤ 参与系统后续优化，扩容方案设计，以支持最高峰值上万的用户


\n① Independently designed and developed the bills module, including database design, deployment to kubernetes, etc. And participate in the implementation of the remaining modules of the team and provide optimization some schemes\n② As Reguard to system maintenance, I have do some deployment monitoring, performance optimization, and troubleshooting. Ensure 99% availability of the system.\n③ Responsible for developing internal tools,For example, package some dockers for automated testing and test environment, developing internal infrastructure distributed scheduling platform, and developing some internal Libraries\n④ do some Devops work, such as setting up maintenance configuration test environment\n⑤ Participate in the follow-up optimization of the system and the design of capacity expansion scheme to support tens of thousands of users at the highest peak


该项目是一个在中国和东南亚拥有300百万用户的搞笑娱乐社区APP, 后端组负责业务推送相关服务推送信息包括文章, 评论, 视频等

The project is a entertainment community app with 300 million users in China and Southeast Asia. The back-end group is responsible for business push related services. The push information includes articles, comments, videos, etc



① 开发和调优,用户历史记录浏览模块,支撑3百万用户新数据的推送，并保证99%的推送信息在0.5-1秒内到达。
② 技术调研, 内部基础平台的调研选型调研,撰写书面报告 
③ 负责一些运营数据的分析和组内对于数据的监控,搭建promethus并收集数据到grafana. 
④ 参与多次在线事故处理


\n① Develop and optimize the user history browsing module to support the data push of 3 million users, and ensure that 99% of the push information arrives within 0.5-1 second.\n② Technical research & selection of internal basic platforms, with the result writen to reports and make open reply\n③ Responsible for the analysis of some operational data analyse, write some script to monitoring data within the group, set up Promethus to collect data and send them to grafana\n④ Participate in multiple online accident handling



group 主要的工作是维护一个搜索引擎,对从上游的每日TB级数据进行同步,然后根据业务和领域进行索引并分库维护数据, 通过很多自动化的脚本,保证日常数据流的正确. 并为其他团队提供数据和相关的查询API


The main work of group is to maintain a search engine, synchronize the TB level of daily data from the upstream, then index and maintain the data according to the business and field, ensure the correction of daily data flow through many automated scripts . Last but not least, provide data and related query APIs for other teams





① 开发和维护自动化脚本,监控各方业务流程流程,必要时手动处理保证流程正确
② 据维护搜索结果优化并撰写书面报告
③ 根据突发流量对各种资源扩容和缩容, 以应对打折促销日支持的突增超过100倍的日增量订单
 ④ 开发业务模块, 定制thrift rpc 对数据进行广播发送。


① Develop and maintain automated scripts, monitor the business processes of all parties, and handle them manually if necessary to ensure that the processes are correct

② Maintain search result optimization and written reports

③ Expand and reduce the capacity of various resources according to the sudden traffic to cope with the sudden increase of daily incremental orders more than 100 times supported on the discount promotion day

④ Develop business module and customize thrift RPC to broadcast and send data.




舰船通信软件, 基于C++ QT库的客户端软件, 移植多平台(linux,window, 国产嵌入式实时操作系统), 该软件用于用户定制军事指令协议,作为一个数据分发的网关, 对数据包的进行协议识别和智能路由

A software that specialisze in communication on warship. This software is used to customize the military instruction protocol for the user. To be a gateway for data distribution, it performs protocol identification and intelligent routing for data packets,which  is based on c++ Qt library. And this software is ported to multiple platforms (Linux, window, domestic embedded real-time operating system)



As the main technich director, independently undertakes the design and development work, realizes simple cluster mutual backup and health check, as well as data synchronization operation, writes project documents, and responsible for subsequent demand communication and iterative development



Introduction
\n① Be familiar with Backend technology and related develop process, be familiar in the environment of Micro service, Cloud-Native , experienced in optimization of sql, or ralated backend performance, though I use them in project frequently.\n② Good coding habit, Focus on code quality, be familiar with mainstream paradigm.\n③ Strong hands-on ability, learn some technology just for interest, willing to work in unfamiliar field, as like to be a backend developer, I may fix some fronted code in work, or I have also done some blockchain related development.\n④ I had solid foundations in data structure and algorithms with decent knowledge of basic computer theory.\n⑤ Proactively understand and solve problems at work, actively communicate, do not set boundaries for me, and have a positive work attitude.







\n① In charge of the bill module, such as database design, cloud deployment. Participated in the implementation and optimization of the other modules as a team member.\n② Responsible for developing the internal infrastructure distributed scheduling platform, some internal libraries, and internal tools, such as packaging some docker images for automated testing and test environments. DevOps work, such as building and maintaining the test environment. do some DevOps work, such as setting up the configuration of the test environment and keep them smoothly , Regarding system maintenance, I have done some deployment monitoring, performance optimization, and troubleshooting. Ensure 99% availability of the system. \n③ Participated in system maintenance, including deployment monitoring, performance optimization, and troubleshooting, to ensure system availability to 99%.\n④ Participated in further system optimization and capacity expansion to support scenarios where users boost to over ten thousand.


\n① In charge of tech and internal-platform research\n② Developed and optimized the user-history module to ensure 99% of the pushing to 3 million users are within 0.5-1 second. \n③ Responsible for data analysis and building the monitoring system with Prometheus and grafana.\n④ Participated in incident handling.


\n① Developed and maintained the  automated scripts, monitored the business flows of all parties, and executed manual correctionscorrection when necessary\n② Analyzed and optimized the system based on the indexing and maintaining outcome.\n③ Implemented the expansion and contraction of various resources to cope with burst traffic, such as the daily order increments by 100 times on promotion days.\n④ Developed business modules, customized thrift rpc for broadcasting.

\n①. Designed and developed the system as the tech director.\n②. Implemented clusters’ mutual backup, health check, and data synchronization.\n③. In charge of user-oriented business analysis, iterative development, and documentation.


\n① In charge of the bill module, such as database design, cloud deployment. Participated in the implementation and optimization of the other modules as a team member\n② Responsible for developing the internal infrastructure distributed scheduling platform,  some internal libraries, and internal tools, such as packaging some docker images for automated testing and test environments. DevOps work, such as building and maintaining the test environment\n③ Participated in system maintenance, including deployment monitoring, performance optimization, and troubleshooting, to ensure system availability to 99%\n④ Participated in further system optimization and capacity expansion to support scenarios where users boost to over 10 times more
